{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Agrupamento Fuzzy\n",
    "\n",
    "### Grupo\n",
    "- Gabriel Camatta Zanotelli - 2018020140\n",
    "- Nander Santos do Carmo - 2018019931"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bibliotecas e dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import skfuzzy\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "sys.path.append(\"./anfis-pytorch/\")\n",
    "from anfispytorch.experimental import train_anfis, test_anfis, plot_all_mfs\n",
    "from anfispytorch.membership import GaussMembFunc, make_gauss_mfs\n",
    "import anfispytorch.anfis1 as ANFIS\n",
    "\n",
    "iris = open('Iris.csv', mode='r')\n",
    "breast = open('Breast.csv', mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2- Aproximação de Funções\n",
    "\n",
    "Utilizaremos um sistema ANFIS de tipo Tageki-Sugueno de Ordem 1 de forma a aproximar uma função na forma sen(x) definida no espaço [0,2] utilizando uma N=80 pontos utilizando a seguinte equação:\n",
    "\n",
    "![Formula senóide com ruído](./senoide.png 'Senóide com ruído')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funções de Pertinência\n",
    "\n",
    "Por experiência temos que, para representar uma senóide de forma precisa, devemos utilizar três regras de pertinência."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Espaço definido\n",
    "N = 80\n",
    "x = np.linspace(0, 2*math.pi, N)\n",
    "\n",
    "# valores de ativação de cada regra\n",
    "fun_pertinencia1 = skfuzzy.gaussmf(x, 0, 1.25)\n",
    "fun_pertinencia2 = skfuzzy.gaussmf(x, math.pi, 1.25)\n",
    "fun_pertinencia3 = skfuzzy.gaussmf(x, 2*math.pi, 1.25)\n",
    "\n",
    "# plota as funções de pertinência\n",
    "plt.plot(x, fun_pertinencia1, x, fun_pertinencia2, x, fun_pertinencia2, x, fun_pertinencia3)\n",
    "plt.title(\"Funções de pertinência da senóide com 3 regras\")\n",
    "plt.xlabel(\"Radianos\")\n",
    "plt.ylabel(\"Pertinência\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geração do conjunto de dados\n",
    "\n",
    "Gera o conjunto de dados aleatórios da senóide e separa conjunto de treino e teste."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gera_dados_treino(size):\n",
    "    perc_train = 0.75\n",
    "    x_space = np.linspace(0, 2*math.pi, size)\n",
    "\n",
    "    # Conjunto de dados de trainamento e teste\n",
    "    x_rand_id = np.linspace(0, size-1, size).astype(int)\n",
    "    rand.shuffle(x_rand_id)\n",
    "\n",
    "    x_train = x_space[x_rand_id[0:int(size*perc_train)]]\n",
    "    x_te = x_space[x_rand_id[int(size*perc_train):size]]\n",
    "\n",
    "    y = np.sin(x_space) + 0.1*np.random.randn(size)\n",
    "    y_train = y[x_rand_id[0:int(size*perc_train)]]\n",
    "    y_te = y[x_rand_id[int(size*perc_train):size]]\n",
    "\n",
    "    # Plota dados de treino (azul) e de teste (laranja)\n",
    "    plt.scatter(x_train,y_train)\n",
    "    plt.scatter(x_te,y_te)\n",
    "\n",
    "    return [x_train, x_te, y_train, y_te]\n",
    "\n",
    "\n",
    "def gera_dados_modelo(x_train, y_train):\n",
    "    x_train_aux = torch.tensor([[val] for val in x_train], dtype=torch.float)\n",
    "    y_train_aux = torch.tensor([[val] for val in y_train], dtype=torch.float)\n",
    "    return DataLoader(TensorDataset(x_train_aux, y_train_aux))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cria modelo ANFIS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def instantiate_problem():\n",
    "    x1 = [('x1', make_gauss_mfs(math.pi/2, [0.0, math.pi, 2*math.pi]))]\n",
    "    x2 = ['x2']\n",
    "    return ANFIS.AnfisNet('Senoide', x1, x2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Executa modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anfis_model = instantiate_problem()\n",
    "dados_treino = gera_dados_treino(N)\n",
    "\n",
    "\n",
    "dados_treino_modelados = gera_dados_modelo(dados_treino[0], dados_treino[2])\n",
    "\n",
    "train_anfis(anfis_model, dados_treino_modelados, N, True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3- Previsão de uma Séria Temporal\n",
    "\n",
    "A série temporal de *Mackey-Glass* é definida pela seguinte formula:\n",
    "\n",
    "![Série de Mackey-Glass](./serie_temporal.png 'Formato da série temporal')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "dados = scipy.io.loadmat('mg.mat')\n",
    "mat = []\n",
    "for i in dados['x']:\n",
    "    mat.append(i[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Training for 100 epochs, training size = 782 cases\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 40\u001B[0m\n\u001B[0;32m     38\u001B[0m model \u001B[38;5;241m=\u001B[39m model_serie()\n\u001B[0;32m     39\u001B[0m train_data \u001B[38;5;241m=\u001B[39m our_data(x_train)\n\u001B[1;32m---> 40\u001B[0m \u001B[43mtrain_anfis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m test_data \u001B[38;5;241m=\u001B[39m our_data(x_test)\n\u001B[0;32m     42\u001B[0m test_anfis(model, test_data, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Desktop\\UFMG\\sistemas-nebulosos\\sistemas nebulosos adaptativos\\anfispytorch\\experimental.py:168\u001B[0m, in \u001B[0;36mtrain_anfis\u001B[1;34m(model, data, epochs, show_plots)\u001B[0m\n\u001B[0;32m    166\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, momentum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.99\u001B[39m)\n\u001B[0;32m    167\u001B[0m criterion \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mMSELoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 168\u001B[0m \u001B[43mtrain_anfis_with\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_plots\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\UFMG\\sistemas-nebulosos\\sistemas nebulosos adaptativos\\anfispytorch\\experimental.py:145\u001B[0m, in \u001B[0;36mtrain_anfis_with\u001B[1;34m(model, data, optimizer, criterion, epochs, show_plots)\u001B[0m\n\u001B[0;32m    143\u001B[0m x, y_actual \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mtensors\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 145\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_coeff\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_actual\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;66;03m# Get the error rate for the whole batch:\u001B[39;00m\n\u001B[0;32m    147\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model(x)\n",
      "File \u001B[1;32m~\\Desktop\\UFMG\\sistemas-nebulosos\\sistemas nebulosos adaptativos\\anfispytorch\\anfis1.py:342\u001B[0m, in \u001B[0;36mAnfisNet.fit_coeff\u001B[1;34m(self, x, y_actual)\u001B[0m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhybrid:\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;28mself\u001B[39m(x)\n\u001B[1;32m--> 342\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mconsequent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_coeff\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_actual\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\UFMG\\sistemas-nebulosos\\sistemas nebulosos adaptativos\\anfispytorch\\anfis1.py:226\u001B[0m, in \u001B[0;36mConsequentLayer.fit_coeff\u001B[1;34m(self, x, weights, y_actual)\u001B[0m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;66;03m# Use gels to do LSE, then pick out the solution rows:\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 226\u001B[0m     coeff_2d, _ \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mlstsq(y_actual_2d, weighted_x_2d)\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInternal error in gels\u001B[39m\u001B[38;5;124m'\u001B[39m, e)\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# loading data set\n",
    "data = loadmat('mg.mat')\n",
    "data = pd.DataFrame(data['x'])\n",
    "sgn = data.values.reshape(-1,)\n",
    "len(sgn)\n",
    "\n",
    "#train test\n",
    "size = len(sgn)\n",
    "train_s = int(size * 0.8)\n",
    "test_s = size - train_s\n",
    "x_train = sgn[:train_s]\n",
    "x_test = sgn[train_s:]\n",
    "\n",
    "def model_serie():\n",
    "    invardefs = [\n",
    "            ('xm18', make_gauss_mfs(0.1, [0.425606, 1.313696])),\n",
    "            ('xm12', make_gauss_mfs(0.1, [0.425606, 1.313696])),\n",
    "            ('xm6',  make_gauss_mfs(0.1, [0.425606, 1.313696])),\n",
    "            ('x',    make_gauss_mfs(0.1, [0.425606, 1.313696])),\n",
    "            ]\n",
    "    outvars = ['xp6']\n",
    "    model = ANFIS.AnfisNet('model_define', invardefs, outvars)\n",
    "    return model\n",
    "\n",
    "\n",
    "def our_data(data):\n",
    "    num_cases = len(data) - 18\n",
    "    x = torch.zeros((num_cases, 4))\n",
    "    y = torch.zeros((num_cases, 1))\n",
    "    for t in range(18, len(data)-6):\n",
    "            values = [data[t-18],data[t-12],data[t-6],data[t],data[t+6]]\n",
    "            x[t-18] = torch.tensor(values[0:4])\n",
    "            y[t-18] = values[4]\n",
    "    dl = DataLoader(TensorDataset(x, y), batch_size=1024, shuffle=True)\n",
    "    return dl\n",
    "\n",
    "\n",
    "model = model_serie()\n",
    "train_data = our_data(x_train)\n",
    "train_anfis(model, train_data, 100, True)\n",
    "test_data = our_data(x_test)\n",
    "test_anfis(model, test_data, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4- Classificação de Padrões"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
